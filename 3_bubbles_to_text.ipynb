{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leer Texto de imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ANACONDA\\envs\\SATURDAYSAI-TENSOR-CV2\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] No se encontró el proceso especificado'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import easyocr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'PIL.Image' has no attribute 'ANTIALIAS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m input_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdivide_images\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Extraer texto de todos los archivos en el directorio\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m extracted_text \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_files_in_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Guardar el texto extraído en un archivo de texto\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124moutput_text\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124moutput_text_easyocr.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m text_file:\n",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m, in \u001b[0;36mprocess_files_in_directory\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     13\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, filename)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.bmp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.gif\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.tiff\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m---> 15\u001b[0m     text_output \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mextract_text_from_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo tiene el formato correcto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m, in \u001b[0;36mextract_text_from_image\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_text_from_image\u001b[39m(image_path):\n\u001b[0;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Extrae texto de una imagen usando EasyOCR\"\"\"\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadtext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(text)\n",
      "File \u001b[1;32me:\\ANACONDA\\envs\\SATURDAYSAI-TENSOR-CV2\\lib\\site-packages\\easyocr\\easyocr.py:464\u001b[0m, in \u001b[0;36mReader.readtext\u001b[1;34m(self, image, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, min_size, contrast_ths, adjust_contrast, filter_ths, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, y_ths, x_ths, add_margin, threshold, bbox_min_score, bbox_min_size, max_candidates, output_format)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;66;03m# get the 1st result from hor & free list as self.detect returns a list of depth 3\u001b[39;00m\n\u001b[0;32m    463\u001b[0m horizontal_list, free_list \u001b[38;5;241m=\u001b[39m horizontal_list[\u001b[38;5;241m0\u001b[39m], free_list[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 464\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_cv_grey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhorizontal_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfree_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeamWidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowlist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocklist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotation_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mparagraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrast_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjust_contrast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mfilter_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32me:\\ANACONDA\\envs\\SATURDAYSAI-TENSOR-CV2\\lib\\site-packages\\easyocr\\easyocr.py:383\u001b[0m, in \u001b[0;36mReader.recognize\u001b[1;34m(self, img_cv_grey, horizontal_list, free_list, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, contrast_ths, adjust_contrast, filter_ths, y_ths, x_ths, reformat, output_format)\u001b[0m\n\u001b[0;32m    381\u001b[0m h_list \u001b[38;5;241m=\u001b[39m [bbox]\n\u001b[0;32m    382\u001b[0m f_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 383\u001b[0m image_list, max_width \u001b[38;5;241m=\u001b[39m \u001b[43mget_image_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_cv_grey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_height\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimgH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m result0 \u001b[38;5;241m=\u001b[39m get_text(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcharacter, imgH, \u001b[38;5;28mint\u001b[39m(max_width), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecognizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconverter, image_list,\\\n\u001b[0;32m    385\u001b[0m               ignore_char, decoder, beamWidth, batch_size, contrast_ths, adjust_contrast, filter_ths,\\\n\u001b[0;32m    386\u001b[0m               workers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    387\u001b[0m result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m result0\n",
      "File \u001b[1;32me:\\ANACONDA\\envs\\SATURDAYSAI-TENSOR-CV2\\lib\\site-packages\\easyocr\\utils.py:613\u001b[0m, in \u001b[0;36mget_image_list\u001b[1;34m(horizontal_list, free_list, img, model_height, sort_output)\u001b[0m\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 613\u001b[0m     crop_img,ratio \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_ratio_and_resize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcrop_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_height\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    614\u001b[0m     image_list\u001b[38;5;241m.\u001b[39mappend( ( [[x_min,y_min],[x_max,y_min],[x_max,y_max],[x_min,y_max]] ,crop_img) )\n\u001b[0;32m    615\u001b[0m     max_ratio_hori \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(ratio, max_ratio_hori)\n",
      "File \u001b[1;32me:\\ANACONDA\\envs\\SATURDAYSAI-TENSOR-CV2\\lib\\site-packages\\easyocr\\utils.py:574\u001b[0m, in \u001b[0;36mcompute_ratio_and_resize\u001b[1;34m(img, width, height, model_height)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ratio\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m    573\u001b[0m     ratio \u001b[38;5;241m=\u001b[39m calculate_ratio(width,height)\n\u001b[1;32m--> 574\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img,(model_height,\u001b[38;5;28mint\u001b[39m(model_height\u001b[38;5;241m*\u001b[39mratio)), interpolation\u001b[38;5;241m=\u001b[39m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mANTIALIAS\u001b[49m)\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    576\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img,(\u001b[38;5;28mint\u001b[39m(model_height\u001b[38;5;241m*\u001b[39mratio),model_height),interpolation\u001b[38;5;241m=\u001b[39mImage\u001b[38;5;241m.\u001b[39mANTIALIAS)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'PIL.Image' has no attribute 'ANTIALIAS'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Inicializar el lector de easyocr\n",
    "reader = easyocr.Reader(['es'])  # 'es' para español, puedes agregar más idiomas según necesidad\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    \"\"\"Extrae texto de una imagen usando EasyOCR\"\"\"\n",
    "    text = reader.readtext(image_path, detail=0)\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "def process_files_in_directory(directory):\n",
    "    \"\"\"Procesa todos los archivos en un directorio y extrae texto de ellos usando EasyOCR\"\"\"\n",
    "    text_output = \"\"\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')):\n",
    "            text_output += extract_text_from_image(file_path) + \"\\n\"\n",
    "        else:\n",
    "            \"No tiene el formato correcto\"\n",
    "    return text_output\n",
    "\n",
    "# Directorio que contiene las imágenes y PDFs\n",
    "input_directory = 'data\\output\\divide_images'\n",
    "\n",
    "# Extraer texto de todos los archivos en el directorio\n",
    "extracted_text = process_files_in_directory(input_directory)\n",
    "\n",
    "# Guardar el texto extraído en un archivo de texto\n",
    "with open('data\\output\\output_text\\output_text_easyocr.txt', 'w', encoding='utf-8') as text_file:\n",
    "    text_file.write(extracted_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SATURDAYSAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
